{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "442132a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 03:25:59.667450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "# !pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fcb863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2995\n",
       "1    1046\n",
       "2     966\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# None=0, Seek=1, Provide=2\n",
    "\n",
    "df = pd.read_csv(\"CSN.csv\")\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2685272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    966\n",
       "1    966\n",
       "2    966\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = df[df['label']==0]\n",
    "df_1 = df[df['label']==1]\n",
    "df_2 = df[df['label']==2]\n",
    "\n",
    "df_0_downsampled = df_0.sample(df_2.shape[0])\n",
    "df_1_downsampled = df_1.sample(df_2.shape[0])\n",
    "\n",
    "df = pd.concat([df_0_downsampled, df_1_downsampled, df_2])\n",
    "# df = pd.concat([df_0_downsampled, df_1])\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db7e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>That is how much time I took off work initally.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>Well, he only has two more chemotherapy treatm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Just one little prick, and that's it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>On the x-ray they can't tell whether it is inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>Your surgeon will tell you when to start exerc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>We will all be along for the ride.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>I am so very sorry that you are suffering ..</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>That has got to be the best news ever, well, e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>There is really nothing anyone can say that is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>Chemo is hard but you will soon be done!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2898 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "4342    That is how much time I took off work initally.      0\n",
       "4142  Well, he only has two more chemotherapy treatm...      0\n",
       "910               Just one little prick, and that's it.      0\n",
       "4296  On the x-ray they can't tell whether it is inf...      0\n",
       "1391  Your surgeon will tell you when to start exerc...      0\n",
       "...                                                 ...    ...\n",
       "4975                 We will all be along for the ride.      2\n",
       "4987       I am so very sorry that you are suffering ..      2\n",
       "4991  That has got to be the best news ever, well, e...      2\n",
       "4993  There is really nothing anyone can say that is...      2\n",
       "4994           Chemo is hard but you will soon be done!      2\n",
       "\n",
       "[2898 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44aee5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       text                                                               \n",
      "      count unique                                                top freq\n",
      "label                                                                     \n",
      "0       966    966    That is how much time I took off work initally.    1\n",
      "1       966    966  i just feel like i am watching him die and i c...    1\n",
      "2       966    966  I just wanted to let you know I was here if yo...    1\n",
      "       text                                                               \n",
      "      count unique                                                top freq\n",
      "label                                                                     \n",
      "0       966    966    That is how much time I took off work initally.    1\n",
      "1       966    966  i just feel like i am watching him die and i c...    1\n",
      "2       966    966  I just wanted to let you know I was here if yo...    1\n",
      "       text                                                               \n",
      "      count unique                                                top freq\n",
      "label                                                                     \n",
      "0      1932   1932    That is how much time I took off work initally.    1\n",
      "1       966    966  i just feel like i am watching him die and i c...    1\n",
      "       text                                                               \n",
      "      count unique                                                top freq\n",
      "label                                                                     \n",
      "0      1932   1932    That is how much time I took off work initally.    1\n",
      "2       966    966  I just wanted to let you know I was here if yo...    1\n",
      "       text                                                               \n",
      "      count unique                                                top freq\n",
      "label                                                                     \n",
      "0      1932   1932    That is how much time I took off work initally.    1\n",
      "1       966    966  I just wanted to let you know I was here if yo...    1\n"
     ]
    }
   ],
   "source": [
    "df_seek = df.copy()\n",
    "print(df_seek.groupby('label').describe())\n",
    "df_response = df.copy()\n",
    "print(df_response.groupby('label').describe())\n",
    "df_seek.loc[df_seek['label'] == 2, 'label'] = 0\n",
    "print(df_seek.groupby('label').describe())\n",
    "df_response.loc[df_response['label'] == 1, 'label'] = 0\n",
    "print(df_response.groupby('label').describe())\n",
    "df_response.loc[df_response['label'] == 2, 'label'] = 1\n",
    "print(df_response.groupby('label').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cd391",
   "metadata": {},
   "source": [
    "TRAINING SEEKER SIDE ON CSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a617288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8bd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 03:26:05.493041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-14 03:26:05.495430: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-14 03:26:05.495468: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "token = tokenizer.encode_plus(\n",
    "    df_seek['text'].iloc[0], \n",
    "    max_length=256, \n",
    "    truncation=True, \n",
    "    padding='max_length', \n",
    "    add_special_tokens=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8e4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids = np.zeros((len(df), 256))\n",
    "X_attn_masks = np.zeros((len(df), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2daeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(df_balanced, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df_seek['text'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b28263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.zeros((len(df_seek), 2))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c3fce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(len(df_seek)), df_seek['label'].values] = 1 # one-hot encoded target te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e93d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "178c25e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " intermediate_layer (Dense)     (None, 512)          393728      ['bert[0][1]']                   \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 2)            1026        ['intermediate_layer[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,705,026\n",
      "Trainable params: 108,705,026\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights\n",
    "\n",
    "# defining 2 input layers for input_ids and attn_masks\n",
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
    "\n",
    "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5736162",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78100448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30e53e2b4fb4519a4111bf8257d694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ad1be3f67340649261641722b8f77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 03:26:21.065675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.7303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 03:30:12.011174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 300s 2s/step - loss: 0.5242 - accuracy: 0.7303 - val_loss: 0.3444 - val_accuracy: 0.8529\n",
      "Epoch 2/2\n",
      "181/181 [==============================] - 280s 2s/step - loss: 0.3587 - accuracy: 0.8484 - val_loss: 0.2443 - val_accuracy: 0.9071\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476ad2c25bf54777af3d70774f83495f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2df9a7bf7214eabba55d6c051a931c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Epoch 1/2\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.9068"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "a=1\n",
    "for train_index, val_index in kf.split(df):\n",
    "    \n",
    "    df_train = df.iloc[train_index]\n",
    "    df_val = df.iloc[val_index]\n",
    "    \n",
    "    X_input_ids_train, X_attn_masks_train = generate_training_data(df_train, X_input_ids, X_attn_masks, tokenizer)\n",
    "    X_input_ids_val, X_attn_masks_val = generate_training_data(df_val, X_input_ids, X_attn_masks, tokenizer)\n",
    "\n",
    "    # creating a data pipeline using tensorflow dataset utility, creates batches of data for easy loading...\n",
    "    dataset_train = tf.data.Dataset.from_tensor_slices((X_input_ids_train, X_attn_masks_train, labels))\n",
    "    dataset_val = tf.data.Dataset.from_tensor_slices((X_input_ids_val, X_attn_masks_val, labels))\n",
    "\n",
    "    dataset_train = dataset_train.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset \n",
    "    dataset_val = dataset_val.map(SentimentDatasetMapFunction)\n",
    "    \n",
    "    dataset_train = dataset_train.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor\n",
    "    dataset_val = dataset_val.shuffle(10000).batch(16, drop_remainder=True)\n",
    "    \n",
    "    print(a)\n",
    "    a = a+1\n",
    "    hist = sentiment_model.fit(dataset_train,validation_data=dataset_val,epochs=2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a20522",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.save('sentiment_model_seek_downsampled_10-fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e5977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seek = pd.read_csv(\"self_eval_seek_2.csv\")\n",
    "test_seek = test_seek[test_seek[\"seeking?\"].notna()]\n",
    "test_seek = test_seek.loc[:, ~test_seek.columns.str.contains('^Unnamed')]\n",
    "test_seek = test_seek.drop_duplicates(subset='seeker_post', keep=\"last\")\n",
    "test_seek.loc[test_seek[\"seeking?\"]==\"Seeking(subtly)\", \"seeking?\"] = int(0)\n",
    "test_seek.loc[test_seek[\"seeking?\"]==\"Not Seeking\", \"seeking?\"] = int(0)\n",
    "test_seek.loc[test_seek[\"seeking?\"]==\"Not Seeking/Maybe\", \"seeking?\"] = int(0)\n",
    "test_seek.loc[test_seek[\"seeking?\"]==\"Seeking(truly)\", \"seeking?\"] = int(1)\n",
    "test_seek[\"seeking?\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_seek = tf.keras.models.load_model('sentiment_model_seek_downsampled_10-fold')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=256, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def predict_class(processed_data):\n",
    "    '''predict class of input text\n",
    "  Args:\n",
    "    - reviews (list of strings)\n",
    "  Output:\n",
    "    - class (list of int)\n",
    "  '''\n",
    "    result = []\n",
    "    for i in processed_data:\n",
    "        pred = sentiment_model_seek.predict(i)\n",
    "        result.append(np.argmax(pred))\n",
    "    return result\n",
    "#     print(sentiment_model_seek.predict(processed_data))\n",
    "#     return [np.argmax(pred) for pred in sentiment_model_seek.predict(processed_data)]\n",
    "#     probs = model.predict(processed_data)[0]\n",
    "#     return classes[np.argmax(probs)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "for i in test_seek[\"seeker_post\"]:\n",
    "    processed_data.append(prepare_data(i, tokenizer))\n",
    "# print(processed_data)\n",
    "y_pred = predict_class(processed_data)\n",
    "print(y_pred)\n",
    "print(classification_report(test_seek[\"seeking?\"].to_list(), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b67eac",
   "metadata": {},
   "source": [
    "TRAINING RESPONSE SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c678cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer.encode_plus(\n",
    "    df_response['text'].iloc[0], \n",
    "    max_length=256, \n",
    "    truncation=True, \n",
    "    padding='max_length', \n",
    "    add_special_tokens=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input_ids = np.zeros((len(df), 256))\n",
    "X_attn_masks = np.zeros((len(df), 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(df_balanced, ids, masks, tokenizer):\n",
    "    for i, text in tqdm(enumerate(df_response['text'])):\n",
    "        tokenized_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            add_special_tokens=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        ids[i, :] = tokenized_text.input_ids\n",
    "        masks[i, :] = tokenized_text.attention_mask\n",
    "    return ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84efa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((len(df_response), 2))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[np.arange(len(df_response)), df_response['label'].values] = 1 # one-hot encoded target te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ea732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentDatasetMapFunction(input_ids, attn_masks, labels):\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attn_masks\n",
    "    }, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a7a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "\n",
    "model = TFBertModel.from_pretrained('bert-base-cased') # bert base model with pretrained weights\n",
    "\n",
    "# defining 2 input layers for input_ids and attn_masks\n",
    "input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
    "intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
    "\n",
    "sentiment_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "sentiment_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5, decay=1e-6)\n",
    "loss_func = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "sentiment_model.compile(optimizer=optim, loss=loss_func, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aef5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "a=1\n",
    "for train_index, val_index in kf.split(df):\n",
    "    \n",
    "    df_train = df.iloc[train_index]\n",
    "    df_val = df.iloc[val_index]\n",
    "    \n",
    "    X_input_ids_train, X_attn_masks_train = generate_training_data(df_train, X_input_ids, X_attn_masks, tokenizer)\n",
    "    X_input_ids_val, X_attn_masks_val = generate_training_data(df_val, X_input_ids, X_attn_masks, tokenizer)\n",
    "\n",
    "    # creating a data pipeline using tensorflow dataset utility, creates batches of data for easy loading...\n",
    "    dataset_train = tf.data.Dataset.from_tensor_slices((X_input_ids_train, X_attn_masks_train, labels))\n",
    "    dataset_val = tf.data.Dataset.from_tensor_slices((X_input_ids_val, X_attn_masks_val, labels))\n",
    "\n",
    "    dataset_train = dataset_train.map(SentimentDatasetMapFunction) # converting to required format for tensorflow dataset \n",
    "    dataset_val = dataset_val.map(SentimentDatasetMapFunction)\n",
    "    \n",
    "    dataset_train = dataset_train.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor\n",
    "    dataset_val = dataset_val.shuffle(10000).batch(16, drop_remainder=True)\n",
    "    \n",
    "    print(a)\n",
    "    a = a+1\n",
    "    hist = sentiment_model.fit(dataset_train,validation_data=dataset_val,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e101aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = sentiment_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b711b2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentiment_model.save('sentiment_model_response_downsampled_10-fold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6dbfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_seek[\"seeking?\"].to_list())\n",
    "print(classification_report(test_seek[\"seeking?\"].to_list(), y_pred))\n",
    "# from sklearn.metrics import confusion_metric\n",
    "# print(confusion_metric(test_set[\"seeking?\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257e0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_response = pd.read_csv(\"Sharma_response_0_1.csv\")\n",
    "# test_response.loc[test_response[\"empathetic?\"]==\"Empathetic\", \"empathetic?\"] = 1\n",
    "# test_response.loc[test_seek[\"empathetic?\"]==\"Non empathetic\", \"empathetic?\"] = 0\n",
    "test_response = test_response.loc[:, ~test_response.columns.str.contains('^Unnamed')]\n",
    "test_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b810ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_seek = tf.keras.models.load_model('sentiment_model_response_downsampled_10-fold')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def prepare_data(input_text, tokenizer):\n",
    "    token = tokenizer.encode_plus(\n",
    "        input_text,\n",
    "        max_length=256, \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        add_special_tokens=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return {\n",
    "        'input_ids': tf.cast(token.input_ids, tf.float64),\n",
    "        'attention_mask': tf.cast(token.attention_mask, tf.float64)\n",
    "    }\n",
    "\n",
    "def predict_class(processed_data):\n",
    "    '''predict class of input text\n",
    "  Args:\n",
    "    - reviews (list of strings)\n",
    "  Output:\n",
    "    - class (list of int)\n",
    "  '''\n",
    "    result = []\n",
    "    for i in processed_data:\n",
    "        pred = sentiment_model_seek.predict(i)\n",
    "        result.append(np.argmax(pred))\n",
    "    return result\n",
    "#     print(sentiment_model_seek.predict(processed_data))\n",
    "#     return [np.argmax(pred) for pred in sentiment_model_seek.predict(processed_data)]\n",
    "#     probs = model.predict(processed_data)[0]\n",
    "#     return classes[np.argmax(probs)]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "processed_data = []\n",
    "\n",
    "for i in test_response[\"response_post\"]:\n",
    "    processed_data.append(prepare_data(i, tokenizer))\n",
    "# print(processed_data)\n",
    "y_pred = predict_class(processed_data)\n",
    "print(y_pred)\n",
    "print(classification_report(test_response[\"level\"].to_list(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_seek[\"seeking?\"].to_list())\n",
    "print(classification_report(test_response[\"level\"].to_list(), y_pred))\n",
    "# from sklearn.metrics import confusion_metric\n",
    "# print(confusion_metric(test_set[\"seeking?\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec40fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(test_seek[\"empathetic?\"].to_list(), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc25da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
